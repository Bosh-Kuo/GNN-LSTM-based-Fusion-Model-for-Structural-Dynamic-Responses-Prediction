{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load single graph data\n",
    "此為單一結構物的 graph data，以類似 dictionary 的結構存取\n",
    "\n",
    "- x: node features\n",
    "- edge_index: node pairs\n",
    "- edge_attr: edge features\n",
    "- Acceleration, Velocity, Desplacement, Moment_Z, Shear_Y, 原始反應歷時資料的 size 皆為 [2000, 8]，因反應立時的取樣頻率為 0.05，最大長度設定為 100 秒，故為 2000 步，8 則是設定最高能預測的建築物樓高。\n",
    "- ground_motion (mm/$s^2$): [time_steps]\n",
    "- time_steps: 未經前處理的 ground motion 步數\n",
    "- sample_rate: 地表加速度資料的取要頻率 (為反應歷時取樣頻率的 10 倍)\n",
    "- ground_motion_name: 地震紀錄名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[147, 15], edge_index=[2, 636], edge_attr=[636, 6], Acceleration=[2000, 8], Velocity=[2000, 8], Displacement=[2000, 8], Moment_Z=[147, 2000, 6], Shear_Y=[147, 2000, 6], ground_motion=[6000], time_steps=6000, sample_rate=0.005, ground_motion_name='1999.09.21_01.47.159_Chichi_TCU011_A900_90.0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "sample_path = \"./Data/Linear_Analysis/eval/ChiChi/structure_401/structure_graph.pt\"\n",
    "sample_graph = torch.load(sample_path)\n",
    "print(sample_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data with GraphDataset\n",
    "- 輸入欲載入的資料集路徑與反應種類\n",
    "- GraphDataset 會進行初步前處理，將結構反應歷時 y 轉為 3 維向量，方便 LSTM model 使用，並存下該結構物樓高與反應種類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from ./Data/Linear_Analysis/ChiChi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:01<00:00,  3.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from ./Data/Linear_Analysis/NGAWest2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:01<00:00,  3.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;32;49m ==================================================================================================== \u001b[0;0m\n",
      "\u001b[0;32;49m  number of effective data: 10 \u001b[0;0m\n",
      "\u001b[0;32;49m ==================================================================================================== \u001b[0;0m\n",
      "Data(x=[147, 15], edge_index=[2, 636], edge_attr=[636, 6], ground_motion=[1, 20000], time_steps=6000, sample_rate=0.005, ground_motion_name='1999.09.21_01.47.159_Chichi_TCU011_A900_90.0', response_type='Velocity', story=6, y=[1, 2000, 8])\n",
      "\n",
      " # of data:10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from Utils.dataset import GraphDataset\n",
    "\n",
    "ChiCHi_folder_dir = \"./Data/Linear_Analysis/eval/ChiChi\"\n",
    "NGAWest2_folder_dir = \"./Data/Linear_Analysis/eval/NGAWest2\"\n",
    "\n",
    "sampleDataset = GraphDataset(folder_path_list = [ChiCHi_folder_dir, NGAWest2_folder_dir], response_type = \"Velocity\", numOfData_per_folder = 5)\n",
    "\n",
    "print(sampleDataset[0])\n",
    "print(f\"\\n # of data:{len(sampleDataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization dictionary\n",
    "資料輸入模型之前需要先經過 normalization 將每個 feature dimention 調整到 [-1, 1]，因此會需要用到各個 feature dimention 的極大值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(source) normalization state: False\n",
      "\n",
      "(target) normalization state: False\n",
      "\n",
      "normalization dictionary: \n",
      " {'x': {'XYZ_gridline_num': tensor(8.), 'XYZ_grid_index': tensor(7.), 'period': tensor(1.2711), 'DOF': tensor(1.), 'mass': tensor(0.0252), 'XYZ_inertia': tensor(255288.), 'XYZ_mode_shape': tensor(2.1000)}, 'ground_motion': tensor(6140.5513), 'y': tensor(2678.), 'edge_attr': {'S_y': tensor(3687090.), 'S_z': tensor(3687090.), 'area': tensor(30774.), 'element_length': tensor(8000.)}, 'response_type': 'Velocity'}\n"
     ]
    }
   ],
   "source": [
    "print(f\"(source) normalization state: {sampleDataset.source_norm_state}\")\n",
    "print(f\"\\n(target) normalization state: {sampleDataset.target_norm_state}\")\n",
    "normalized_item_dict = sampleDataset.get_normalized_item_dict()\n",
    "print(\"\\nnormalization dictionary: \\n\", normalized_item_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noramalize\n",
    "以各個 feature dimention 的極大值來 normalize 資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(source) normalization state: True\n",
      "\n",
      "(target) normalization state: True\n"
     ]
    }
   ],
   "source": [
    "sampleDataset.normalize_source(normalized_item_dict)\n",
    "sampleDataset.normalize_target(normalized_item_dict)\n",
    "print(f\"(source) normalization state: {sampleDataset.source_norm_state}\")\n",
    "print(f\"\\n(target) normalization state: {sampleDataset.target_norm_state}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Denormalize\n",
    "模型計算完後再將計算結果 demormalize 回原本的 scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(source) normalization state: False\n",
      "\n",
      "(target) normalization state: False\n"
     ]
    }
   ],
   "source": [
    "sampleDataset.denormalize_source(normalized_item_dict)\n",
    "sampleDataset.denormalize_target(normalized_item_dict)\n",
    "print(f\"(source) normalization state: {sampleDataset.source_norm_state}\")\n",
    "print(f\"\\n(target) normalization state: {sampleDataset.target_norm_state}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoader (PyG)\n",
    "以 DataLoader 作為迭代器，訓練時 batch size 可以任意調整，shuffle=True；預測時 batch size = 1 ，shuffle=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======\n",
      "mini batch 0:\n",
      "DataBatch(x=[147, 15], edge_index=[2, 636], edge_attr=[636, 6], ground_motion=[1, 20000], time_steps=[1], sample_rate=[1], ground_motion_name=[1], response_type=[1], story=[1], y=[1, 2000, 8], batch=[147], ptr=[2])\n",
      "\n",
      "=======\n",
      "mini batch 1:\n",
      "DataBatch(x=[210, 15], edge_index=[2, 904], edge_attr=[904, 6], ground_motion=[1, 20000], time_steps=[1], sample_rate=[1], ground_motion_name=[1], response_type=[1], story=[1], y=[1, 2000, 8], batch=[210], ptr=[2])\n",
      "\n",
      "=======\n",
      "mini batch 2:\n",
      "DataBatch(x=[168, 15], edge_index=[2, 742], edge_attr=[742, 6], ground_motion=[1, 20000], time_steps=[1], sample_rate=[1], ground_motion_name=[1], response_type=[1], story=[1], y=[1, 2000, 8], batch=[168], ptr=[2])\n",
      "\n",
      "=======\n",
      "mini batch 3:\n",
      "DataBatch(x=[105, 15], edge_index=[2, 444], edge_attr=[444, 6], ground_motion=[1, 20000], time_steps=[1], sample_rate=[1], ground_motion_name=[1], response_type=[1], story=[1], y=[1, 2000, 8], batch=[105], ptr=[2])\n",
      "\n",
      "=======\n",
      "mini batch 4:\n",
      "DataBatch(x=[245, 15], edge_index=[2, 1116], edge_attr=[1116, 6], ground_motion=[1, 20000], time_steps=[1], sample_rate=[1], ground_motion_name=[1], response_type=[1], story=[1], y=[1, 2000, 8], batch=[245], ptr=[2])\n",
      "\n",
      "=======\n",
      "mini batch 5:\n",
      "DataBatch(x=[168, 15], edge_index=[2, 742], edge_attr=[742, 6], ground_motion=[1, 20000], time_steps=[1], sample_rate=[1], ground_motion_name=[1], response_type=[1], story=[1], y=[1, 2000, 8], batch=[168], ptr=[2])\n",
      "\n",
      "=======\n",
      "mini batch 6:\n",
      "DataBatch(x=[336, 15], edge_index=[2, 1582], edge_attr=[1582, 6], ground_motion=[1, 20000], time_steps=[1], sample_rate=[1], ground_motion_name=[1], response_type=[1], story=[1], y=[1, 2000, 8], batch=[336], ptr=[2])\n",
      "\n",
      "=======\n",
      "mini batch 7:\n",
      "DataBatch(x=[192, 15], edge_index=[2, 868], edge_attr=[868, 6], ground_motion=[1, 20000], time_steps=[1], sample_rate=[1], ground_motion_name=[1], response_type=[1], story=[1], y=[1, 2000, 8], batch=[192], ptr=[2])\n",
      "\n",
      "=======\n",
      "mini batch 8:\n",
      "DataBatch(x=[144, 15], edge_index=[2, 630], edge_attr=[630, 6], ground_motion=[1, 20000], time_steps=[1], sample_rate=[1], ground_motion_name=[1], response_type=[1], story=[1], y=[1, 2000, 8], batch=[144], ptr=[2])\n",
      "\n",
      "=======\n",
      "mini batch 9:\n",
      "DataBatch(x=[63, 15], edge_index=[2, 252], edge_attr=[252, 6], ground_motion=[1, 20000], time_steps=[1], sample_rate=[1], ground_motion_name=[1], response_type=[1], story=[1], y=[1, 2000, 8], batch=[63], ptr=[2])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.loader import DataLoader as GraphDataLoader\n",
    "exclude_keys=[\"sample_rate\", \"ground_motion_name\", \"response_type\"]\n",
    "sample_loader = GraphDataLoader(sampleDataset, batch_size=1, shuffle=False, )\n",
    "\n",
    "for (i, data) in enumerate(sample_loader):\n",
    "    print('=======')\n",
    "    print(f'mini batch {i}:' )\n",
    "    # data = data.to(\"cuda\")\n",
    "    print(data)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pack and Pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======\n",
      "mini-batch:\n",
      "DataBatch(x=[147, 15], edge_index=[2, 636], edge_attr=[636, 6], ground_motion=[1, 20000], time_steps=[1], sample_rate=[1], ground_motion_name=[1], response_type=[1], story=[1], y=[1, 2000, 8], batch=[147], ptr=[2])\n",
      "\n",
      "=======\n",
      "size of compressed ground motion:\n",
      "torch.Size([1, 1000, 20])\n",
      "\n",
      "PPS length list:\n",
      "tensor([300.])\n",
      "\n",
      "=======\n",
      "size of unpacked ground motion:\n",
      "torch.Size([1, 1000, 20])\n",
      "\n",
      "check x has unpacked to original format\n",
      "True\n",
      "\n",
      "unpack length list:\n",
      "tensor([300])\n"
     ]
    }
   ],
   "source": [
    "compression_rate = 20\n",
    "data = next(iter(sample_loader))\n",
    "ground_motion = data.ground_motion.reshape(-1, int(data.ground_motion.size(1)/compression_rate), compression_rate)\n",
    "ground_motion = ground_motion.to(\"cuda\")\n",
    "\n",
    "packed_length_list = data.time_steps / compression_rate\n",
    "total_length = ground_motion.size(1)\n",
    "print('=======')\n",
    "print(\"mini-batch:\")\n",
    "print(data)\n",
    "print()\n",
    "\n",
    "print('=======')\n",
    "print(\"size of compressed ground motion:\")\n",
    "print(ground_motion.size())\n",
    "print()\n",
    "print(\"PPS length list:\")\n",
    "print(packed_length_list)\n",
    "print()\n",
    "\n",
    "packed_x = nn.utils.rnn.pack_padded_sequence(ground_motion, lengths = packed_length_list, batch_first=True, enforce_sorted=False)\n",
    "seq_unpacked_x, lens_unpacked = nn.utils.rnn.pad_packed_sequence(packed_x, batch_first=True, total_length = total_length)\n",
    "\n",
    "print('=======')\n",
    "print(\"size of unpacked ground motion:\")\n",
    "print(seq_unpacked_x.size())\n",
    "print()\n",
    "print(\"check x has unpacked to original format\")\n",
    "print(torch.equal(seq_unpacked_x, ground_motion))\n",
    "print()\n",
    "print(\"unpack length list:\")\n",
    "print(lens_unpacked)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7411dda26440847be1ecf0282c7bf158e15f6b8673c85bc211b4f5d7508ca037"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
